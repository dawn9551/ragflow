# Deep ResearchèŠå¤©æ¨¡å¼é›†æˆå®ç°æŒ‡å—

> **åˆ›å»ºæ—¶é—´**: 2025-01-08  
> **ç›®æ ‡**: å°†Deep Researchä½œä¸ºèŠå¤©æ—¶çš„ç‹¬ç«‹é€‰é¡¹é›†æˆåˆ°RAGFlowä¸­  
> **å®ç°èŒƒå›´**: å‰ç«¯UI + åç«¯API + æ•°æ®æµè®¾è®¡  

---

## ç›®å½•

1. [éœ€æ±‚åˆ†æ](#éœ€æ±‚åˆ†æ)
2. [æ•´ä½“æ¶æ„è®¾è®¡](#æ•´ä½“æ¶æ„è®¾è®¡)
3. [åç«¯å®ç°æ–¹æ¡ˆ](#åç«¯å®ç°æ–¹æ¡ˆ)
4. [å‰ç«¯å®ç°æ–¹æ¡ˆ](#å‰ç«¯å®ç°æ–¹æ¡ˆ)
5. [æ•°æ®åº“è®¾è®¡è°ƒæ•´](#æ•°æ®åº“è®¾è®¡è°ƒæ•´)
6. [é…ç½®å’Œéƒ¨ç½²](#é…ç½®å’Œéƒ¨ç½²)
7. [æµ‹è¯•éªŒè¯](#æµ‹è¯•éªŒè¯)

---

## éœ€æ±‚åˆ†æ

### åŠŸèƒ½éœ€æ±‚
- **ç”¨æˆ·ç•Œé¢**: åœ¨èŠå¤©ç•Œé¢æ·»åŠ "Deep Research"æ¨¡å¼é€‰æ‹©å™¨
- **è¾“å…¥å¤„ç†**: æ¥æ”¶ç”¨æˆ·é—®é¢˜ï¼Œè§¦å‘Deep Researchæµç¨‹
- **å¤šæºæ£€ç´¢**: è‡ªåŠ¨æ£€ç´¢Web + æœ¬åœ°çŸ¥è¯†åº“ + çŸ¥è¯†å›¾è°±
- **æµå¼è¾“å‡º**: å®æ—¶æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹å’Œæœç´¢è¿›åº¦
- **ç»“æœå±•ç¤º**: ç”Ÿæˆç»“æ„åŒ–çš„ç ”ç©¶æŠ¥å‘Š
- **å†å²è®°å½•**: ä¿å­˜Deep Researchä¼šè¯å†å²

### æŠ€æœ¯éœ€æ±‚
- **å…¼å®¹æ€§**: ä¸ç°æœ‰èŠå¤©ç³»ç»Ÿæ— ç¼é›†æˆ
- **æ€§èƒ½**: æ”¯æŒå¹¶å‘Deep Researchè¯·æ±‚
- **å¯é…ç½®**: æ”¯æŒå‚æ•°è°ƒä¼˜å’ŒåŠŸèƒ½å¼€å…³
- **æ‰©å±•æ€§**: ä¾¿äºæ·»åŠ æ–°çš„æ•°æ®æºå’ŒåŠŸèƒ½

---

## æ•´ä½“æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å‰ç«¯ (React)   â”‚   åç«¯ (Flask)   â”‚   æ•°æ®å±‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ èŠå¤©ç•Œé¢å¢å¼º     â”‚ Deep Research    â”‚ ä¼šè¯å­˜å‚¨         â”‚
â”‚ â”œâ”€ æ¨¡å¼é€‰æ‹©å™¨   â”‚ APIç«¯ç‚¹          â”‚ â”œâ”€ å¯¹è¯è®°å½•     â”‚
â”‚ â”œâ”€ æµå¼æ˜¾ç¤º     â”‚ â”œâ”€ /chat/deep    â”‚ â”œâ”€ æ¨ç†æ­¥éª¤     â”‚
â”‚ â”œâ”€ è¿›åº¦æŒ‡ç¤º     â”‚ â”œâ”€ æµå¼å¤„ç†      â”‚ â””â”€ æ£€ç´¢ç»“æœ     â”‚
â”‚ â””â”€ æŠ¥å‘Šå±•ç¤º     â”‚ â””â”€ é”™è¯¯å¤„ç†      â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ é…ç½®ç•Œé¢        â”‚ DeepResearcher   â”‚ çŸ¥è¯†åº“          â”‚
â”‚ â”œâ”€ å‚æ•°è®¾ç½®     â”‚ é›†æˆå±‚           â”‚ â”œâ”€ å‘é‡æ•°æ®åº“   â”‚
â”‚ â”œâ”€ æ•°æ®æºé…ç½®   â”‚ â”œâ”€ çŸ¥è¯†åº“æ£€ç´¢    â”‚ â”œâ”€ çŸ¥è¯†å›¾è°±     â”‚
â”‚ â””â”€ APIå¯†é’¥ç®¡ç†  â”‚ â”œâ”€ Webæœç´¢       â”‚ â””â”€ æ–‡æ¡£å­˜å‚¨     â”‚
â”‚                 â”‚ â””â”€ çŸ¥è¯†å›¾è°±æŸ¥è¯¢  â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµè®¾è®¡

```
ç”¨æˆ·è¾“å…¥é—®é¢˜
    â†“
é€‰æ‹©Deep Researchæ¨¡å¼
    â†“
å‰ç«¯å‘é€è¯·æ±‚åˆ° /api/v1/chat/deep_research
    â†“
åç«¯åˆ›å»ºDeepResearcherå®ä¾‹
    â†“
å¼€å§‹å¤šè½®æ¨ç†å¾ªç¯
    â”œâ”€ ç”Ÿæˆæ¨ç†æ­¥éª¤
    â”œâ”€ æå–æœç´¢æŸ¥è¯¢  
    â”œâ”€ å¤šæºä¿¡æ¯æ£€ç´¢
    â”‚   â”œâ”€ çŸ¥è¯†åº“æ£€ç´¢
    â”‚   â”œâ”€ Webæœç´¢ (Tavily)
    â”‚   â””â”€ çŸ¥è¯†å›¾è°±æŸ¥è¯¢
    â”œâ”€ ä¿¡æ¯æå–æ€»ç»“
    â””â”€ æµå¼è¿”å›ç»“æœ
    â†“
å‰ç«¯å®æ—¶æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
    â†“
ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š
    â†“
ä¿å­˜ä¼šè¯å†å²
```

---

## åç«¯å®ç°æ–¹æ¡ˆ

### 1. åˆ›å»ºDeep Research APIç«¯ç‚¹

#### æ–°å»ºæ–‡ä»¶: `api/apps/deep_research_app.py`

```python
#
#  Copyright 2024 The InfiniFlow Authors. All Rights Reserved.
#
import json
import logging
from flask import Blueprint, request, Response
from flask_login import login_required, current_user
from functools import partial

from agentic_reasoning.deep_research import DeepResearcher
from api.db.services.dialog_service import DialogService, ConversationService
from api.db.services.llm_service import LLMBundle, TenantLLMService
from api.db.services.knowledgebase_service import KnowledgebaseService
from api.utils.api_utils import server_error_response, validate_request
from api.utils.file_utils import get_project_base_directory
from rag.app import naive
from rag.nlp import search
from rag.utils import rmSpace
from rag.utils.redis_conn import REDIS_CONN
from graphrag.search import kg_search


bp = Blueprint('deep_research_app', __name__, url_prefix='/api/v1/chat')


class DeepResearchChatService:
    """Deep ResearchèŠå¤©æœåŠ¡"""
    
    def __init__(self):
        self.dialog_service = DialogService()
        self.conversation_service = ConversationService()
        self.kb_service = KnowledgebaseService()
    
    def create_deep_researcher(self, dialog_id: str, question: str):
        """åˆ›å»ºDeepResearcherå®ä¾‹"""
        # è·å–å¯¹è¯é…ç½®
        dialog = self.dialog_service.get_by_id(dialog_id)
        if not dialog:
            raise ValueError("Dialog not found")
        
        # è·å–LLMé…ç½®
        llm_id = dialog.llm_id or "qwen-max@Tongyi-Qianwen"  # é»˜è®¤LLM
        chat_mdl = LLMBundle(dialog.tenant_id, 
                           TenantLLMService.llm_id2llm_type(llm_id),
                           llm_id)
        
        # è·å–prompté…ç½®
        prompt_config = dialog.prompt_config or {}
        
        # çŸ¥è¯†åº“æ£€ç´¢å‡½æ•°
        kb_retrieve = None
        if dialog.kb_ids:
            kb_retrieve = partial(
                self._kb_retrieve,
                dialog_id=dialog_id,
                kb_ids=dialog.kb_ids,
                tenant_id=dialog.tenant_id
            )
        
        # çŸ¥è¯†å›¾è°±æ£€ç´¢å‡½æ•°  
        kg_retrieve = None
        if prompt_config.get("use_kg", False):
            kg_retrieve = partial(
                self._kg_retrieve,
                tenant_id=dialog.tenant_id,
                kb_ids=dialog.kb_ids
            )
        
        return DeepResearcher(
            chat_mdl=chat_mdl,
            prompt_config=prompt_config,
            kb_retrieve=kb_retrieve,
            kg_retrieve=kg_retrieve
        )
    
    def _kb_retrieve(self, question: str, dialog_id: str, kb_ids: list, tenant_id: str):
        """çŸ¥è¯†åº“æ£€ç´¢"""
        try:
            kbinfos = {"chunks": [], "doc_aggs": []}
            
            for kb_id in kb_ids:
                kb = self.kb_service.get_by_id(kb_id)
                if not kb:
                    continue
                
                # æ‰§è¡Œæ£€ç´¢
                retr = naive.retrieval(
                    question, 
                    kb.embd_id, 
                    kb.tenant_id, 
                    kb_id, 
                    1, 
                    kb.parser_config.get("top_n", 8),
                    kb.parser_config.get("similarity_threshold", 0.2),
                    kb.parser_config.get("vector_similarity_weight", 0.3),
                    doc_ids=kb.doc_ids if hasattr(kb, 'doc_ids') else []
                )
                
                if retr.get("chunks"):
                    kbinfos["chunks"].extend(retr["chunks"])
                if retr.get("doc_aggs"):
                    kbinfos["doc_aggs"].extend(retr["doc_aggs"])
            
            return kbinfos
            
        except Exception as e:
            logging.error(f"Knowledge base retrieval error: {e}")
            return {"chunks": [], "doc_aggs": []}
    
    def _kg_retrieve(self, question: str, tenant_id: str, kb_ids: list):
        """çŸ¥è¯†å›¾è°±æ£€ç´¢"""
        try:
            if not kb_ids:
                return {"content_with_weight": ""}
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªçŸ¥è¯†åº“è¿›è¡Œå›¾è°±æ£€ç´¢
            kb_id = kb_ids[0]
            kg_res = kg_search(question, kb_id, tenant_id)
            
            return {"content_with_weight": kg_res}
            
        except Exception as e:
            logging.error(f"Knowledge graph retrieval error: {e}")
            return {"content_with_weight": ""}
    
    def save_conversation(self, dialog_id: str, question: str, answer: str, 
                         research_steps: list = None):
        """ä¿å­˜å¯¹è¯è®°å½•"""
        try:
            conversation = {
                "role": "user",
                "content": question,
                "id": f"user_{int(time.time() * 1000)}"
            }
            self.conversation_service.save(dialog_id, conversation)
            
            assistant_conversation = {
                "role": "assistant", 
                "content": answer,
                "id": f"assistant_{int(time.time() * 1000)}",
                "research_mode": "deep_research",
                "research_steps": research_steps or []
            }
            self.conversation_service.save(dialog_id, assistant_conversation)
            
        except Exception as e:
            logging.error(f"Save conversation error: {e}")


@bp.route('/deep_research', methods=['POST'])
@login_required
@validate_request("dialog_id", "question")
def deep_research_chat():
    """Deep ResearchèŠå¤©API"""
    try:
        req = request.json
        dialog_id = req["dialog_id"]
        question = req["question"]
        
        # éªŒè¯æƒé™
        dialog = DialogService.get_by_id(dialog_id)
        if not dialog or dialog.tenant_id != current_user.id:
            return server_error_response("Dialog not found or access denied")
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        service = DeepResearchChatService()
        
        def generate_response():
            """ç”Ÿæˆæµå¼å“åº”"""
            chunk_info = {"chunks": [], "doc_aggs": []}  # ç”¨äºæ”¶é›†å¼•ç”¨ä¿¡æ¯
            research_steps = []  # è®°å½•ç ”ç©¶æ­¥éª¤
            final_answer = ""
            
            try:
                # åˆ›å»ºDeepResearcher
                researcher = service.create_deep_researcher(dialog_id, question)
                
                # å‘é€å¼€å§‹äº‹ä»¶
                yield f"data: {json.dumps({'event': 'start', 'data': {'question': question}}, ensure_ascii=False)}\n\n"
                
                # å¼€å§‹æ·±åº¦ç ”ç©¶
                step_count = 0
                for result in researcher.thinking(chunk_info, question):
                    if isinstance(result, dict) and "answer" in result:
                        answer_content = result["answer"]
                        
                        # æå–æ¨ç†æ­¥éª¤
                        if answer_content.startswith("<think>") and answer_content.endswith("</think>"):
                            thinking_content = answer_content[7:-8]  # å»é™¤<think>æ ‡è®°
                            
                            # å‘é€æ¨ç†æ­¥éª¤
                            step_data = {
                                "event": "thinking_step",
                                "data": {
                                    "step": step_count,
                                    "content": thinking_content,
                                    "timestamp": int(time.time() * 1000)
                                }
                            }
                            yield f"data: {json.dumps(step_data, ensure_ascii=False)}\n\n"
                            
                            research_steps.append({
                                "step": step_count,
                                "content": thinking_content,
                                "timestamp": int(time.time() * 1000)
                            })
                            step_count += 1
                    
                    elif isinstance(result, str):
                        # æœ€ç»ˆç­”æ¡ˆ
                        final_answer = result
                        if final_answer.startswith("<think>") and final_answer.endswith("</think>"):
                            final_answer = final_answer[7:-8]
                
                # å‘é€æœ€ç»ˆç»“æœ
                final_data = {
                    "event": "final_answer",
                    "data": {
                        "answer": final_answer,
                        "references": {
                            "chunks": chunk_info.get("chunks", []),
                            "doc_aggs": chunk_info.get("doc_aggs", [])
                        },
                        "research_steps": research_steps
                    }
                }
                yield f"data: {json.dumps(final_data, ensure_ascii=False)}\n\n"
                
                # ä¿å­˜å¯¹è¯
                service.save_conversation(dialog_id, question, final_answer, research_steps)
                
                # å‘é€å®Œæˆäº‹ä»¶
                yield f"data: {json.dumps({'event': 'complete'}, ensure_ascii=False)}\n\n"
                
            except Exception as e:
                logging.error(f"Deep research error: {e}")
                error_data = {
                    "event": "error",
                    "data": {"message": str(e)}
                }
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
        
        return Response(
            generate_response(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'X-Accel-Buffering': 'no'
            }
        )
        
    except Exception as e:
        return server_error_response(e)


@bp.route('/deep_research/config', methods=['GET', 'POST'])
@login_required  
def deep_research_config():
    """Deep Researché…ç½®ç®¡ç†"""
    try:
        if request.method == 'GET':
            # è·å–å½“å‰é…ç½®
            dialog_id = request.args.get('dialog_id')
            if not dialog_id:
                return server_error_response("Dialog ID required")
            
            dialog = DialogService.get_by_id(dialog_id)
            if not dialog or dialog.tenant_id != current_user.id:
                return server_error_response("Dialog not found or access denied")
            
            config = dialog.prompt_config or {}
            deep_research_config = {
                "enabled": config.get("reasoning", False),
                "tavily_api_key": config.get("tavily_api_key", ""),
                "use_kg": config.get("use_kg", False),
                "max_search_rounds": config.get("max_search_rounds", 6),
                "temperature": config.get("temperature", 0.7)
            }
            
            return {"retcode": 0, "data": deep_research_config}
        
        elif request.method == 'POST':
            # æ›´æ–°é…ç½®
            req = request.json
            dialog_id = req.get("dialog_id")
            config = req.get("config", {})
            
            if not dialog_id:
                return server_error_response("Dialog ID required")
            
            dialog = DialogService.get_by_id(dialog_id)
            if not dialog or dialog.tenant_id != current_user.id:
                return server_error_response("Dialog not found or access denied")
            
            # æ›´æ–°prompt_config
            prompt_config = dialog.prompt_config or {}
            prompt_config.update({
                "reasoning": config.get("enabled", False),
                "tavily_api_key": config.get("tavily_api_key", ""),
                "use_kg": config.get("use_kg", False), 
                "max_search_rounds": config.get("max_search_rounds", 6),
                "temperature": config.get("temperature", 0.7)
            })
            
            DialogService.update_by_id(dialog_id, {"prompt_config": prompt_config})
            
            return {"retcode": 0, "data": {"message": "Configuration updated successfully"}}
            
    except Exception as e:
        return server_error_response(e)
```

### 2. æ³¨å†ŒAPIè·¯ç”±

#### ä¿®æ”¹æ–‡ä»¶: `api/ragflow_server.py`

```python
# åœ¨ç°æœ‰çš„Blueprintæ³¨å†Œéƒ¨åˆ†æ·»åŠ 
from api.apps.deep_research_app import bp as deep_research_bp

# æ³¨å†ŒDeep Research Blueprint
app.register_blueprint(deep_research_bp)
```

### 3. æ‰©å±•Dialogæ¨¡å‹

#### ä¿®æ”¹æ–‡ä»¶: `api/db/db_models.py`

```python
# åœ¨Dialogç±»ä¸­æ·»åŠ æ–°å­—æ®µï¼ˆå¦‚æœéœ€è¦ï¼‰
class Dialog(DataBaseModel):
    # ... ç°æœ‰å­—æ®µ
    
    # æ·»åŠ Deep Researchç›¸å…³é…ç½®
    deep_research_enabled = BooleanField(default=False)  # æ˜¯å¦å¯ç”¨Deep Research
    deep_research_config = TextField(default='{}')       # Deep Researché…ç½®JSON
```

---

## å‰ç«¯å®ç°æ–¹æ¡ˆ

### 1. èŠå¤©æ¨¡å¼é€‰æ‹©å™¨ç»„ä»¶

#### æ–°å»ºæ–‡ä»¶: `web/src/components/chat-mode-selector/index.tsx`

```tsx
import React from 'react';
import { Select, Switch, Tooltip } from 'antd';
import { BrainIcon, MessageCircleIcon, SearchIcon } from 'lucide-react';
import { useTranslation } from 'react-i18next';

export enum ChatMode {
  NORMAL = 'normal',
  DEEP_RESEARCH = 'deep_research'
}

interface ChatModeSelectorProps {
  mode: ChatMode;
  onChange: (mode: ChatMode) => void;
  disabled?: boolean;
}

const ChatModeSelector: React.FC<ChatModeSelectorProps> = ({
  mode,
  onChange,
  disabled = false
}) => {
  const { t } = useTranslation();

  const chatModeOptions = [
    {
      value: ChatMode.NORMAL,
      label: t('chat.mode.normal'),
      icon: <MessageCircleIcon size={16} />,
      description: t('chat.mode.normal.description')
    },
    {
      value: ChatMode.DEEP_RESEARCH,
      label: t('chat.mode.deepResearch'),
      icon: <BrainIcon size={16} />,
      description: t('chat.mode.deepResearch.description')
    }
  ];

  return (
    <div className="flex items-center space-x-4 p-2 bg-gray-50 rounded-lg">
      <span className="text-sm font-medium text-gray-700">
        {t('chat.mode.title')}:
      </span>
      
      <Select
        value={mode}
        onChange={onChange}
        disabled={disabled}
        className="min-w-[200px]"
        optionLabelProp="label"
      >
        {chatModeOptions.map((option) => (
          <Select.Option key={option.value} value={option.value} label={
            <div className="flex items-center space-x-2">
              {option.icon}
              <span>{option.label}</span>
            </div>
          }>
            <div className="flex items-start space-x-3 py-2">
              <div className="flex-shrink-0 mt-1">
                {option.icon}
              </div>
              <div>
                <div className="font-medium">{option.label}</div>
                <div className="text-sm text-gray-500">{option.description}</div>
              </div>
            </div>
          </Select.Option>
        ))}
      </Select>

      {mode === ChatMode.DEEP_RESEARCH && (
        <Tooltip title={t('chat.mode.deepResearch.tooltip')}>
          <div className="flex items-center space-x-1 text-blue-600">
            <SearchIcon size={14} />
            <span className="text-xs">{t('chat.mode.deepResearch.active')}</span>
          </div>
        </Tooltip>
      )}
    </div>
  );
};

export default ChatModeSelector;
```

### 2. Deep Researchæ¶ˆæ¯ç»„ä»¶

#### æ–°å»ºæ–‡ä»¶: `web/src/components/deep-research-message/index.tsx`

```tsx
import React, { useState } from 'react';
import { Card, Collapse, Timeline, Tag, Button, Divider } from 'antd';
import { BrainIcon, SearchIcon, FileTextIcon, ChevronDownIcon, ChevronUpIcon } from 'lucide-react';
import { useTranslation } from 'react-i18next';
import MarkdownContent from '@/components/next-markdown-content';

interface ResearchStep {
  step: number;
  content: string;
  timestamp: number;
}

interface Reference {
  chunks: any[];
  doc_aggs: any[];
}

interface DeepResearchMessageProps {
  answer: string;
  researchSteps: ResearchStep[];
  references: Reference;
  loading?: boolean;
  currentStep?: number;
}

const DeepResearchMessage: React.FC<DeepResearchMessageProps> = ({
  answer,
  researchSteps,
  references,
  loading = false,
  currentStep = -1
}) => {
  const { t } = useTranslation();
  const [showSteps, setShowSteps] = useState(false);
  const [showReferences, setShowReferences] = useState(false);

  const formatTimestamp = (timestamp: number) => {
    return new Date(timestamp).toLocaleTimeString();
  };

  const renderThinkingProcess = () => {
    if (!researchSteps || researchSteps.length === 0) return null;

    return (
      <Card
        size="small"
        className="mb-4"
        title={
          <div className="flex items-center space-x-2">
            <BrainIcon size={16} className="text-blue-500" />
            <span>{t('deepResearch.thinkingProcess')}</span>
            <Tag color="blue">{researchSteps.length} {t('deepResearch.steps')}</Tag>
          </div>
        }
        extra={
          <Button
            type="text"
            size="small"
            icon={showSteps ? <ChevronUpIcon size={14} /> : <ChevronDownIcon size={14} />}
            onClick={() => setShowSteps(!showSteps)}
          >
            {showSteps ? t('common.collapse') : t('common.expand')}
          </Button>
        }
      >
        <Collapse ghost activeKey={showSteps ? ['steps'] : []}>
          <Collapse.Panel key="steps" header="" showArrow={false}>
            <Timeline>
              {researchSteps.map((step, index) => (
                <Timeline.Item
                  key={step.step}
                  color={
                    loading && index === currentStep
                      ? 'blue'
                      : index <= currentStep
                      ? 'green'
                      : 'gray'
                  }
                  dot={
                    loading && index === currentStep ? (
                      <SearchIcon size={12} className="animate-spin" />
                    ) : (
                      <span className="w-2 h-2 rounded-full bg-current" />
                    )
                  }
                >
                  <div className="pb-4">
                    <div className="flex items-center space-x-2 mb-2">
                      <span className="font-medium text-gray-900">
                        {t('deepResearch.step')} {step.step + 1}
                      </span>
                      <span className="text-xs text-gray-500">
                        {formatTimestamp(step.timestamp)}
                      </span>
                    </div>
                    <div className="text-sm text-gray-700 whitespace-pre-wrap">
                      {step.content}
                    </div>
                  </div>
                </Timeline.Item>
              ))}
            </Timeline>
          </Collapse.Panel>
        </Collapse>
      </Card>
    );
  };

  const renderReferences = () => {
    if (!references || (!references.chunks?.length && !references.doc_aggs?.length)) {
      return null;
    }

    return (
      <Card
        size="small"
        className="mt-4"
        title={
          <div className="flex items-center space-x-2">
            <FileTextIcon size={16} className="text-green-500" />
            <span>{t('deepResearch.references')}</span>
            <Tag color="green">
              {(references.chunks?.length || 0) + (references.doc_aggs?.length || 0)} {t('deepResearch.sources')}
            </Tag>
          </div>
        }
        extra={
          <Button
            type="text"
            size="small"
            icon={showReferences ? <ChevronUpIcon size={14} /> : <ChevronDownIcon size={14} />}
            onClick={() => setShowReferences(!showReferences)}
          >
            {showReferences ? t('common.collapse') : t('common.expand')}
          </Button>
        }
      >
        <Collapse ghost activeKey={showReferences ? ['references'] : []}>
          <Collapse.Panel key="references" header="" showArrow={false}>
            <div className="space-y-3">
              {references.chunks?.map((chunk, index) => (
                <div key={index} className="p-3 bg-gray-50 rounded-lg">
                  <div className="flex items-center space-x-2 mb-2">
                    <Tag size="small" color="blue">KB</Tag>
                    <span className="font-medium text-sm">{chunk.doc_name}</span>
                  </div>
                  <div className="text-sm text-gray-700 line-clamp-3">
                    {chunk.content_with_weight}
                  </div>
                </div>
              ))}
              
              {references.doc_aggs?.map((doc, index) => (
                <div key={index} className="p-3 bg-blue-50 rounded-lg">
                  <div className="flex items-center space-x-2 mb-2">
                    <Tag size="small" color="green">WEB</Tag>
                    <span className="font-medium text-sm">{doc.doc_name}</span>
                  </div>
                  <div className="text-sm text-gray-700">
                    {doc.doc_name}
                  </div>
                </div>
              ))}
            </div>
          </Collapse.Panel>
        </Collapse>
      </Card>
    );
  };

  return (
    <div className="deep-research-message">
      {renderThinkingProcess()}
      
      <div className="research-answer">
        <Card 
          title={
            <div className="flex items-center space-x-2">
              <BrainIcon size={16} className="text-purple-500" />
              <span>{t('deepResearch.researchReport')}</span>
            </div>
          }
          className="mb-4"
        >
          <MarkdownContent content={answer} />
        </Card>
      </div>

      {renderReferences()}
    </div>
  );
};

export default DeepResearchMessage;
```

### 3. èŠå¤©ç•Œé¢é›†æˆ

#### ä¿®æ”¹æ–‡ä»¶: `web/src/pages/chat/index.tsx`

```tsx
import React, { useState, useEffect } from 'react';
import { useParams } from 'umi';
import ChatModeSelector, { ChatMode } from '@/components/chat-mode-selector';
import DeepResearchMessage from '@/components/deep-research-message';
import { useSendMessage } from '@/hooks/use-send-message';

const ChatPage: React.FC = () => {
  const { id: dialogId } = useParams();
  const [chatMode, setChatMode] = useState<ChatMode>(ChatMode.NORMAL);
  const [isDeepResearching, setIsDeepResearching] = useState(false);
  const [currentResearchStep, setCurrentResearchStep] = useState(-1);
  const [researchSteps, setResearchSteps] = useState([]);
  
  const { sendMessage, sendingLoading } = useSendMessage();

  // Deep Researchä¸“ç”¨å‘é€æ¶ˆæ¯å‡½æ•°
  const sendDeepResearchMessage = async (message: string) => {
    if (!dialogId) return;

    setIsDeepResearching(true);
    setCurrentResearchStep(0);
    setResearchSteps([]);

    try {
      const response = await fetch('/api/v1/chat/deep_research', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          dialog_id: dialogId,
          question: message
        })
      });

      if (!response.ok) {
        throw new Error('Deep research request failed');
      }

      const reader = response.body?.getReader();
      if (!reader) return;

      let finalAnswer = '';
      let references = { chunks: [], doc_aggs: [] };
      const steps = [];

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = new TextDecoder().decode(value);
        const lines = chunk.split('\n');

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6));
              
              switch (data.event) {
                case 'start':
                  console.log('Deep research started:', data.data);
                  break;
                  
                case 'thinking_step':
                  steps.push(data.data);
                  setResearchSteps([...steps]);
                  setCurrentResearchStep(data.data.step);
                  break;
                  
                case 'final_answer':
                  finalAnswer = data.data.answer;
                  references = data.data.references;
                  setResearchSteps(data.data.research_steps);
                  break;
                  
                case 'error':
                  console.error('Deep research error:', data.data.message);
                  break;
                  
                case 'complete':
                  setIsDeepResearching(false);
                  setCurrentResearchStep(-1);
                  break;
              }
            } catch (e) {
              console.error('Failed to parse SSE data:', e);
            }
          }
        }
      }

      // æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
      if (finalAnswer) {
        // è¿™é‡Œéœ€è¦æ ¹æ®ä½ çš„çŠ¶æ€ç®¡ç†æ–¹å¼æ¥æ›´æ–°æ¶ˆæ¯åˆ—è¡¨
        // addMessage({
        //   role: 'assistant',
        //   content: finalAnswer,
        //   research_mode: 'deep_research',
        //   research_steps: steps,
        //   references: references
        // });
      }

    } catch (error) {
      console.error('Deep research error:', error);
      setIsDeepResearching(false);
    }
  };

  // å¤„ç†æ¶ˆæ¯å‘é€
  const handleSendMessage = async (message: string) => {
    if (chatMode === ChatMode.DEEP_RESEARCH) {
      await sendDeepResearchMessage(message);
    } else {
      await sendMessage(message);
    }
  };

  // æ¸²æŸ“æ¶ˆæ¯ç»„ä»¶
  const renderMessage = (message: any) => {
    if (message.research_mode === 'deep_research') {
      return (
        <DeepResearchMessage
          answer={message.content}
          researchSteps={message.research_steps || []}
          references={message.references || { chunks: [], doc_aggs: [] }}
          loading={isDeepResearching}
          currentStep={currentResearchStep}
        />
      );
    }
    
    // æ™®é€šæ¶ˆæ¯æ¸²æŸ“é€»è¾‘
    return <div>{message.content}</div>;
  };

  return (
    <div className="chat-container">
      {/* èŠå¤©æ¨¡å¼é€‰æ‹©å™¨ */}
      <div className="chat-header p-4 border-b">
        <ChatModeSelector
          mode={chatMode}
          onChange={setChatMode}
          disabled={sendingLoading || isDeepResearching}
        />
      </div>

      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <div className="messages-container flex-1 overflow-y-auto p-4">
        {/* æ¸²æŸ“æ¶ˆæ¯åˆ—è¡¨ */}
        {/* messages.map(renderMessage) */}
      </div>

      {/* è¾“å…¥åŒºåŸŸ */}
      <div className="chat-input-container p-4 border-t">
        {/* 
          æ ¹æ®chatModeæ˜¾ç¤ºä¸åŒçš„è¾“å…¥æç¤º
          Deep Researchæ¨¡å¼ä¸‹å¯ä»¥æ˜¾ç¤ºç‰¹æ®Šçš„å ä½ç¬¦æ–‡æœ¬
        */}
        <MessageInput
          onSend={handleSendMessage}
          disabled={sendingLoading || isDeepResearching}
          placeholder={
            chatMode === ChatMode.DEEP_RESEARCH
              ? t('chat.input.deepResearch.placeholder')
              : t('chat.input.normal.placeholder')
          }
        />
      </div>
    </div>
  );
};

export default ChatPage;
```

### 4. å¤šè¯­è¨€æ”¯æŒ

#### ä¿®æ”¹æ–‡ä»¶: `web/src/locales/zh.ts`

```typescript
export default {
  // ... ç°æœ‰ç¿»è¯‘
  
  chat: {
    mode: {
      title: 'èŠå¤©æ¨¡å¼',
      normal: 'æ™®é€šèŠå¤©',
      deepResearch: 'æ·±åº¦ç ”ç©¶',
      'normal.description': 'å¿«é€Ÿå¯¹è¯ï¼ŒåŸºäºçŸ¥è¯†åº“ç›´æ¥å›ç­”',
      'deepResearch.description': 'æ·±åº¦ç ”ç©¶æ¨¡å¼ï¼Œå¤šæºæ£€ç´¢ï¼Œè¯¦ç»†åˆ†æ',
      'deepResearch.tooltip': 'å½“å‰å¤„äºæ·±åº¦ç ”ç©¶æ¨¡å¼',
      'deepResearch.active': 'ç ”ç©¶ä¸­'
    },
    input: {
      'normal.placeholder': 'è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...',
      'deepResearch.placeholder': 'è¯·è¾“å…¥éœ€è¦æ·±åº¦ç ”ç©¶çš„é—®é¢˜ï¼Œæˆ‘å°†ä¸ºæ‚¨è¿›è¡Œå…¨é¢åˆ†æ...'
    }
  },
  
  deepResearch: {
    thinkingProcess: 'æ€è€ƒè¿‡ç¨‹',
    steps: 'æ­¥éª¤',
    step: 'æ­¥éª¤',
    researchReport: 'ç ”ç©¶æŠ¥å‘Š',
    references: 'å‚è€ƒèµ„æ–™',
    sources: 'æ¥æº',
    analyzing: 'æ­£åœ¨åˆ†æ...',
    searching: 'æ­£åœ¨æœç´¢...',
    synthesizing: 'æ­£åœ¨ç»¼åˆä¿¡æ¯...'
  }
};
```

#### ä¿®æ”¹æ–‡ä»¶: `web/src/locales/en.ts`

```typescript
export default {
  // ... existing translations
  
  chat: {
    mode: {
      title: 'Chat Mode',
      normal: 'Normal Chat',
      deepResearch: 'Deep Research',
      'normal.description': 'Quick conversation based on knowledge base',
      'deepResearch.description': 'Deep research mode with multi-source retrieval and detailed analysis',
      'deepResearch.tooltip': 'Currently in deep research mode',
      'deepResearch.active': 'Researching'
    },
    input: {
      'normal.placeholder': 'Enter your question...',
      'deepResearch.placeholder': 'Enter a question for deep research, I will provide comprehensive analysis...'
    }
  },
  
  deepResearch: {
    thinkingProcess: 'Thinking Process',
    steps: 'Steps',
    step: 'Step',
    researchReport: 'Research Report',
    references: 'References',
    sources: 'Sources',
    analyzing: 'Analyzing...',
    searching: 'Searching...',
    synthesizing: 'Synthesizing information...'
  }
};
```

---

## æ•°æ®åº“è®¾è®¡è°ƒæ•´

### 1. æ‰©å±•Dialogè¡¨

```sql
-- æ·»åŠ Deep Researchç›¸å…³å­—æ®µ
ALTER TABLE dialog ADD COLUMN deep_research_enabled BOOLEAN DEFAULT FALSE;
ALTER TABLE dialog ADD COLUMN deep_research_config TEXT DEFAULT '{}';

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_dialog_deep_research ON dialog(deep_research_enabled);
```

### 2. æ‰©å±•Conversationè¡¨

```sql  
-- æ·»åŠ ç ”ç©¶æ¨¡å¼æ ‡è¯†
ALTER TABLE conversation ADD COLUMN research_mode VARCHAR(50) DEFAULT NULL;
ALTER TABLE conversation ADD COLUMN research_steps TEXT DEFAULT NULL;
ALTER TABLE conversation ADD COLUMN research_references TEXT DEFAULT NULL;

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_conversation_research_mode ON conversation(research_mode);
```

### 3. åˆ›å»ºDeep Researché…ç½®è¡¨ (å¯é€‰)

```sql
-- åˆ›å»ºDeep Researchå…¨å±€é…ç½®è¡¨
CREATE TABLE deep_research_config (
    id VARCHAR(128) PRIMARY KEY,
    tenant_id VARCHAR(128) NOT NULL,
    config_name VARCHAR(128) NOT NULL,
    config_value TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (tenant_id) REFERENCES tenant(id) ON DELETE CASCADE
);

CREATE INDEX idx_deep_research_config_tenant ON deep_research_config(tenant_id);
```

---

## é…ç½®å’Œéƒ¨ç½²

### 1. ç¯å¢ƒå˜é‡é…ç½®

#### ä¿®æ”¹æ–‡ä»¶: `docker/.env`

```bash
# Deep Researchç›¸å…³é…ç½®
DEEP_RESEARCH_ENABLED=true
DEEP_RESEARCH_MAX_ROUNDS=6
DEEP_RESEARCH_TEMPERATURE=0.7

# Tavily APIé…ç½® (å¯é€‰)
TAVILY_API_KEY=your_tavily_api_key_here
```

### 2. æœåŠ¡é…ç½®

#### ä¿®æ”¹æ–‡ä»¶: `docker/service_conf.yaml.template`

```yaml
# Deep Researché…ç½®
deep_research:
  enabled: ${DEEP_RESEARCH_ENABLED:-true}
  max_rounds: ${DEEP_RESEARCH_MAX_ROUNDS:-6}
  temperature: ${DEEP_RESEARCH_TEMPERATURE:-0.7}
  
  # é»˜è®¤æ•°æ®æºé…ç½®
  data_sources:
    knowledge_base:
      enabled: true
      weight: 0.4
    web_search:
      enabled: true
      weight: 0.4
      api_key: ${TAVILY_API_KEY:-""}
    knowledge_graph:
      enabled: true
      weight: 0.2
```

### 3. Dockeré…ç½®æ›´æ–°

#### ä¿®æ”¹æ–‡ä»¶: `docker/docker-compose.yml`

```yaml
version: '3.8'
services:
  ragflow:
    # ... ç°æœ‰é…ç½®
    environment:
      # ... ç°æœ‰ç¯å¢ƒå˜é‡
      - DEEP_RESEARCH_ENABLED=${DEEP_RESEARCH_ENABLED:-true}
      - DEEP_RESEARCH_MAX_ROUNDS=${DEEP_RESEARCH_MAX_ROUNDS:-6}
      - TAVILY_API_KEY=${TAVILY_API_KEY:-""}
```

---

## æµ‹è¯•éªŒè¯

### 1. å•å…ƒæµ‹è¯•

#### æ–°å»ºæ–‡ä»¶: `test/testcases/test_deep_research/test_deep_research_api.py`

```python
import pytest
import json
from test.libs.auth import login_test_user
from test.testcases.test_http_api.common import request_json


class TestDeepResearchAPI:
    
    def test_deep_research_chat(self):
        """æµ‹è¯•Deep ResearchèŠå¤©åŠŸèƒ½"""
        # ç™»å½•
        login_test_user()
        
        # åˆ›å»ºæµ‹è¯•å¯¹è¯
        dialog_data = {
            "name": "Deep Research Test Dialog",
            "kb_ids": []
        }
        dialog_response = request_json('/api/v1/dialog', 'POST', dialog_data)
        assert dialog_response['retcode'] == 0
        dialog_id = dialog_response['data']['id']
        
        # å‘é€Deep Researchè¯·æ±‚
        research_data = {
            "dialog_id": dialog_id,
            "question": "What are the latest developments in artificial intelligence?"
        }
        
        response = request_json('/api/v1/chat/deep_research', 'POST', research_data)
        # ç”±äºæ˜¯æµå¼å“åº”ï¼Œè¿™é‡Œéœ€è¦ç‰¹æ®Šå¤„ç†
        assert response.status_code == 200
        assert response.headers.get('content-type') == 'text/event-stream; charset=utf-8'
    
    def test_deep_research_config(self):
        """æµ‹è¯•Deep Researché…ç½®ç®¡ç†"""
        # ç™»å½•
        login_test_user()
        
        # åˆ›å»ºæµ‹è¯•å¯¹è¯
        dialog_data = {
            "name": "Config Test Dialog",
            "kb_ids": []
        }
        dialog_response = request_json('/api/v1/dialog', 'POST', dialog_data)
        dialog_id = dialog_response['data']['id']
        
        # è·å–é…ç½®
        config_response = request_json(f'/api/v1/chat/deep_research/config?dialog_id={dialog_id}', 'GET')
        assert config_response['retcode'] == 0
        
        # æ›´æ–°é…ç½®
        new_config = {
            "dialog_id": dialog_id,
            "config": {
                "enabled": True,
                "tavily_api_key": "test_key",
                "use_kg": True,
                "max_search_rounds": 8
            }
        }
        
        update_response = request_json('/api/v1/chat/deep_research/config', 'POST', new_config)
        assert update_response['retcode'] == 0
```

### 2. å‰ç«¯ç»„ä»¶æµ‹è¯•

#### æ–°å»ºæ–‡ä»¶: `web/src/components/chat-mode-selector/__tests__/index.test.tsx`

```tsx
import React from 'react';
import { render, screen, fireEvent } from '@testing-library/react';
import ChatModeSelector, { ChatMode } from '../index';

describe('ChatModeSelector', () => {
  const mockOnChange = jest.fn();

  beforeEach(() => {
    mockOnChange.mockClear();
  });

  test('renders correctly with normal mode', () => {
    render(
      <ChatModeSelector
        mode={ChatMode.NORMAL}
        onChange={mockOnChange}
      />
    );

    expect(screen.getByText('Normal Chat')).toBeInTheDocument();
  });

  test('renders correctly with deep research mode', () => {
    render(
      <ChatModeSelector
        mode={ChatMode.DEEP_RESEARCH}
        onChange={mockOnChange}
      />
    );

    expect(screen.getByText('Deep Research')).toBeInTheDocument();
    expect(screen.getByText('Researching')).toBeInTheDocument();
  });

  test('calls onChange when mode is changed', () => {
    render(
      <ChatModeSelector
        mode={ChatMode.NORMAL}
        onChange={mockOnChange}
      />
    );

    // æ¨¡æ‹Ÿé€‰æ‹©Deep Researchæ¨¡å¼
    fireEvent.click(screen.getByText('Normal Chat'));
    fireEvent.click(screen.getByText('Deep Research'));

    expect(mockOnChange).toHaveBeenCalledWith(ChatMode.DEEP_RESEARCH);
  });

  test('is disabled when disabled prop is true', () => {
    render(
      <ChatModeSelector
        mode={ChatMode.NORMAL}
        onChange={mockOnChange}
        disabled={true}
      />
    );

    const selector = screen.getByRole('combobox');
    expect(selector).toBeDisabled();
  });
});
```

### 3. é›†æˆæµ‹è¯•è„šæœ¬

#### æ–°å»ºæ–‡ä»¶: `test/deep_research_integration_test.py`

```python
#!/usr/bin/env python3
"""Deep Researché›†æˆæµ‹è¯•è„šæœ¬"""

import requests
import json
import time
from urllib.parse import urljoin


class DeepResearchIntegrationTest:
    
    def __init__(self, base_url='http://localhost'):
        self.base_url = base_url
        self.session = requests.Session()
        self.dialog_id = None
    
    def login(self, email='test@ragflow.io', password='test123'):
        """ç™»å½•æµ‹è¯•ç”¨æˆ·"""
        login_data = {
            'email': email,
            'password': password
        }
        response = self.session.post(
            urljoin(self.base_url, '/api/v1/user/login'),
            json=login_data
        )
        assert response.status_code == 200
        result = response.json()
        assert result['retcode'] == 0
        print("âœ“ ç™»å½•æˆåŠŸ")
        return result
    
    def create_dialog(self):
        """åˆ›å»ºæµ‹è¯•å¯¹è¯"""
        dialog_data = {
            'name': 'Deep Research Integration Test',
            'kb_ids': []
        }
        response = self.session.post(
            urljoin(self.base_url, '/api/v1/dialog'),
            json=dialog_data
        )
        assert response.status_code == 200
        result = response.json()
        assert result['retcode'] == 0
        self.dialog_id = result['data']['id']
        print(f"âœ“ åˆ›å»ºå¯¹è¯æˆåŠŸ: {self.dialog_id}")
        return result
    
    def test_deep_research_config(self):
        """æµ‹è¯•Deep Researché…ç½®"""
        # è·å–å½“å‰é…ç½®
        response = self.session.get(
            urljoin(self.base_url, f'/api/v1/chat/deep_research/config?dialog_id={self.dialog_id}')
        )
        assert response.status_code == 200
        result = response.json()
        assert result['retcode'] == 0
        print("âœ“ è·å–é…ç½®æˆåŠŸ")
        
        # æ›´æ–°é…ç½®
        config_data = {
            'dialog_id': self.dialog_id,
            'config': {
                'enabled': True,
                'tavily_api_key': 'test_key',
                'use_kg': False,
                'max_search_rounds': 6,
                'temperature': 0.7
            }
        }
        response = self.session.post(
            urljoin(self.base_url, '/api/v1/chat/deep_research/config'),
            json=config_data
        )
        assert response.status_code == 200
        result = response.json()
        assert result['retcode'] == 0
        print("âœ“ æ›´æ–°é…ç½®æˆåŠŸ")
    
    def test_deep_research_chat(self):
        """æµ‹è¯•Deep ResearchèŠå¤©"""
        research_data = {
            'dialog_id': self.dialog_id,
            'question': 'What are the key advantages of RAG systems in AI applications?'
        }
        
        response = self.session.post(
            urljoin(self.base_url, '/api/v1/chat/deep_research'),
            json=research_data,
            stream=True
        )
        
        assert response.status_code == 200
        assert 'text/event-stream' in response.headers.get('content-type', '')
        
        events = []
        for line in response.iter_lines(decode_unicode=True):
            if line.startswith('data: '):
                try:
                    event_data = json.loads(line[6:])
                    events.append(event_data)
                    print(f"ğŸ“¡ æ”¶åˆ°äº‹ä»¶: {event_data.get('event', 'unknown')}")
                    
                    if event_data.get('event') == 'complete':
                        break
                except json.JSONDecodeError:
                    continue
        
        # éªŒè¯äº‹ä»¶åºåˆ—
        event_types = [event.get('event') for event in events]
        assert 'start' in event_types
        assert 'thinking_step' in event_types or 'final_answer' in event_types
        assert 'complete' in event_types
        
        print("âœ“ Deep ResearchèŠå¤©æµ‹è¯•æˆåŠŸ")
        return events
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹Deep Researché›†æˆæµ‹è¯•")
        
        try:
            self.login()
            self.create_dialog()
            self.test_deep_research_config()
            self.test_deep_research_chat()
            
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            raise


if __name__ == '__main__':
    test = DeepResearchIntegrationTest()
    test.run_all_tests()
```

---

## å®æ–½æ­¥éª¤å»ºè®®

### ç¬¬ä¸€é˜¶æ®µï¼šåç«¯åŸºç¡€å®ç° (é¢„è®¡2-3å¤©)
1. âœ… åˆ›å»º `api/apps/deep_research_app.py`
2. âœ… å®ç° `DeepResearchChatService` ç±»
3. âœ… æ·»åŠ APIè·¯ç”±æ³¨å†Œ
4. âœ… æ•°æ®åº“Schemaè°ƒæ•´
5. âœ… åŸºç¡€é…ç½®ç®¡ç†

### ç¬¬äºŒé˜¶æ®µï¼šå‰ç«¯ç»„ä»¶å¼€å‘ (é¢„è®¡2-3å¤©) 
1. âœ… å¼€å‘ `ChatModeSelector` ç»„ä»¶
2. âœ… å¼€å‘ `DeepResearchMessage` ç»„ä»¶
3. âœ… é›†æˆåˆ°èŠå¤©ç•Œé¢
4. âœ… å¤šè¯­è¨€æ”¯æŒ
5. âœ… æ ·å¼å’Œäº¤äº’ä¼˜åŒ–

### ç¬¬ä¸‰é˜¶æ®µï¼šé›†æˆæµ‹è¯•å’Œä¼˜åŒ– (é¢„è®¡1-2å¤©)
1. âœ… å•å…ƒæµ‹è¯•ç¼–å†™
2. âœ… é›†æˆæµ‹è¯•éªŒè¯
3. âœ… æ€§èƒ½ä¼˜åŒ–
4. âœ… é”™è¯¯å¤„ç†å®Œå–„
5. âœ… æ–‡æ¡£æ›´æ–°

### ç¬¬å››é˜¶æ®µï¼šéƒ¨ç½²å’Œç›‘æ§ (é¢„è®¡1å¤©)
1. âœ… ç”Ÿäº§ç¯å¢ƒé…ç½®
2. âœ… ç›‘æ§å’Œæ—¥å¿—
3. âœ… ç”¨æˆ·åŸ¹è®­
4. âœ… åé¦ˆæ”¶é›†

---

## æ³¨æ„äº‹é¡¹å’Œé£é™©

### æŠ€æœ¯é£é™©
1. **æµå¼å“åº”å¤„ç†**: ç¡®ä¿å‰ç«¯æ­£ç¡®å¤„ç†SSEäº‹ä»¶æµ
2. **å¹¶å‘æ§åˆ¶**: Deep Researchå¯èƒ½æ¶ˆè€—è¾ƒå¤šèµ„æºï¼Œéœ€è¦è€ƒè™‘å¹¶å‘é™åˆ¶
3. **è¶…æ—¶ç®¡ç†**: è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´é¿å…é•¿æ—¶é—´ç­‰å¾…
4. **é”™è¯¯æ¢å¤**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º

### ç”¨æˆ·ä½“éªŒé£é™©
1. **ç­‰å¾…æ—¶é—´**: Deep Researchå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œéœ€è¦æ¸…æ™°çš„è¿›åº¦æŒ‡ç¤º
2. **æ¨¡å¼åˆ‡æ¢**: ç¡®ä¿ç”¨æˆ·ç†è§£ä¸åŒèŠå¤©æ¨¡å¼çš„åŒºåˆ«
3. **ç»“æœå±•ç¤º**: å¤æ‚çš„ç ”ç©¶ç»“æœéœ€è¦æ¸…æ™°çš„ç»“æ„åŒ–å±•ç¤º

### è¿ç»´é£é™©
1. **èµ„æºæ¶ˆè€—**: Deep Researchæ¨¡å¼å¯èƒ½æ¶ˆè€—æ›´å¤šAPIè°ƒç”¨å’Œè®¡ç®—èµ„æº
2. **APIé™åˆ¶**: ç¬¬ä¸‰æ–¹æœåŠ¡(å¦‚Tavily)çš„APIé™åˆ¶éœ€è¦è€ƒè™‘
3. **å­˜å‚¨å¢é•¿**: ç ”ç©¶æ­¥éª¤å’Œç»“æœå¯èƒ½å¢åŠ æ•°æ®åº“å­˜å‚¨éœ€æ±‚

---

## æ‰©å±•è®¡åˆ’

### çŸ­æœŸæ‰©å±• (1-2å‘¨)
- æ·»åŠ ç ”ç©¶æŠ¥å‘Šå¯¼å‡ºåŠŸèƒ½ (PDF/Word)
- æ”¯æŒè‡ªå®šä¹‰ç ”ç©¶æ¨¡æ¿
- å¢åŠ ç ”ç©¶å†å²ç®¡ç†
- æ·»åŠ ç ”ç©¶è´¨é‡è¯„åˆ†

### ä¸­æœŸæ‰©å±• (1-2æœˆ)
- æ”¯æŒå¤šè¯­è¨€ç ”ç©¶
- é›†æˆæ›´å¤šæ•°æ®æº (å­¦æœ¯æ•°æ®åº“ã€ä¸“ä¸šæ•°æ®æº)
- æ·»åŠ åä½œç ”ç©¶åŠŸèƒ½
- å®ç°ç ”ç©¶æŠ¥å‘Šåˆ†äº«

### é•¿æœŸæ‰©å±• (3-6æœˆ)
- AIé©±åŠ¨çš„ç ”ç©¶è§„åˆ’
- è‡ªåŠ¨åŒ–ç ”ç©¶å·¥ä½œæµ
- ç ”ç©¶ç»“æœéªŒè¯ç³»ç»Ÿ
- é›†æˆå¤–éƒ¨åˆ†æå·¥å…·

---

è¿™ä¸ªå®ç°æŒ‡å—æä¾›äº†å°†Deep Researché›†æˆä¸ºèŠå¤©é€‰é¡¹çš„å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆã€‚é€šè¿‡è¿™ç§è®¾è®¡ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ™®é€šèŠå¤©å’Œæ·±åº¦ç ”ç©¶ä¹‹é—´çµæ´»åˆ‡æ¢ï¼Œè·å¾—ä¸åŒæ·±åº¦çš„AI assistanceã€‚æ•´ä¸ªå®ç°ä¿æŒäº†ä¸ç°æœ‰ç³»ç»Ÿçš„å…¼å®¹æ€§ï¼ŒåŒæ—¶æä¾›äº†ä¸°å¯Œçš„æ‰©å±•å¯èƒ½æ€§ã€‚